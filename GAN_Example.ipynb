{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-Example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pB95ZdVXYPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5fNqBd1XdnL",
        "colab_type": "code",
        "outputId": "725eeb1b-931c-4591-d82f-fc7457011046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmdtdQKC8qXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2GyCivXYloX",
        "colab_type": "code",
        "outputId": "4a31f86c-04b0-428e-ca08-17520f6df0ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx6H5OPCyiRa",
        "colab_type": "code",
        "outputId": "07719d9e-e832-483c-9e63-cdfb50d1a575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# mnist-Modified National Institute of Standards and Technology database\n",
        "# it is a large database of handwritten digits that is commonly used for training various image processing systems\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/content/drive/My Drive/Colab Notebooks/MNIST/mnist_krishnaik\",one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-de2830d83e36>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /content/drive/My Drive/Colab Notebooks/MNIST/mnist_krishnaik/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /content/drive/My Drive/Colab Notebooks/MNIST/mnist_krishnaik/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting /content/drive/My Drive/Colab Notebooks/MNIST/mnist_krishnaik/t10k-images-idx3-ubyte.gz\n",
            "Extracting /content/drive/My Drive/Colab Notebooks/MNIST/mnist_krishnaik/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmG8MAVGyo7X",
        "colab_type": "code",
        "outputId": "8dfb2804-0d66-4b60-9124-25c770d783ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(mnist.train.images[0].reshape(28,28),cmap='Greys')\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe270085dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR6HAHoiytFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS9J7I7g0Q2S",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI0wC9W10RtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(z,reuse=None):   # z is the latent data point \n",
        "    with tf.variable_scope('gen',reuse=reuse):   # variable scope is gen\n",
        "        hidden1 = tf.layers.dense(inputs=z,units=128) # 1st hidden layer and units is how many neurons\n",
        "        # Leaky Relu     \n",
        "        alpha = 0.01\n",
        "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
        "\n",
        "\n",
        "        hidden2 = tf.layers.dense(inputs=hidden1,units=128) # 2nd hidden layer\n",
        "        hidden2 = tf.maximum(alpha*hidden2,hidden2) # leaky relu\n",
        "\n",
        "        output = tf.layers.dense(hidden2,units=784,activation=tf.nn.tanh) # output layer  784=28*28(image size)\n",
        "        return output                       # tanh activation function to the output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLuPew3L0UEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmE1asEk0ZEr",
        "colab_type": "text"
      },
      "source": [
        "The Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EobAttTy0Zxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator(X,reuse=None):   # same as generator\n",
        "    with tf.variable_scope('dis',reuse=reuse):\n",
        "        hidden1 = tf.layers.dense(inputs=X,units=128)\n",
        "        # Leaky Relu\n",
        "        alpha = 0.01\n",
        "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
        "        \n",
        "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
        "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
        "        \n",
        "        logits = tf.layers.dense(hidden2,units=1)\n",
        "        output = tf.sigmoid(logits) # here we use sigmoid function(only 2 outcomes ie. 0 or 1)\n",
        "    \n",
        "        return output, logits   # it gives 2 outputs one is logits value and 2nd is image is real or ake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB0KStzE0cGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ka_nU9l0jTi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_WJa0u0q7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_images = tf.placeholder(tf.float32,shape=[None,784])# creates the place holder which gives images to the descriminator  \n",
        "# tf.float32 because mnist are numpy arrays,  \n",
        "# 784=28*28  one image dimension\n",
        "\n",
        "\n",
        "z = tf.placeholder(tf.float32,shape=[None,100])\n",
        "# creates the place holder which gives images to the generator\n",
        "# z is a noise, we some noise to generator with [None,100] dimensions.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31CJntRT0r0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONRp0Y2U2p2K",
        "colab_type": "text"
      },
      "source": [
        "Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2zm9FUW2rW7",
        "colab_type": "code",
        "outputId": "0b1e7a13-fbdf-4917-9b19-ca2b568a8b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "G = generator(z) # call the generator function"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-e7685126ebef>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfKlK2S42taN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwcazQym8ycz",
        "colab_type": "text"
      },
      "source": [
        "Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPbduvJF8zH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_output_real , D_logits_real = discriminator(real_images) # call the Discriminator function\n",
        "# 1st give real_images to discriminator to train the model\n",
        "# D_output_real , D_logits_real are output of discriminator on real_images  \n",
        "\n",
        "\n",
        "\n",
        "D_output_fake, D_logits_fake = discriminator(G,reuse=True)\n",
        "# after that give noise to the discriminator for testing (latent data points)\n",
        "# D_output_fake, D_logits_fake are output of discriminator on latent points\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlSlIUFC8-Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sstkENKv_MU4",
        "colab_type": "text"
      },
      "source": [
        "Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nq7rDl99CS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_func(logits_in,labels_in):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))\n",
        "# loss function is help us to find out most optimat point in our training time \n",
        "#  sigmoid_cross_entropy is our loss function   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSDysmplAWO6",
        "colab_type": "code",
        "outputId": "b556cf52-69d1-4068-c43e-b10724f3330d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real)* (0.9))\n",
        "D_real_loss\n",
        "\n",
        "# tf.ones_like(D_logits_real) gives 1 number and 0.9 indicates smoothing(near to 1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tV2VGjvAfCD",
        "colab_type": "code",
        "outputId": "c0082baf-8eb0-4450-c31c-7c1cc7792e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_real))\n",
        "D_fake_loss\n",
        "# tf.zeros_like these are fake so zero(treated as fake)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean_1:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQTCHWzfAkTE",
        "colab_type": "code",
        "outputId": "6c920866-175d-469f-c28a-b21b4293dd30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "D_loss = D_real_loss + D_fake_loss\n",
        "D_loss\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk-rFXllAoqm",
        "colab_type": "code",
        "outputId": "90996cbf-4546-4ab7-9a18-205c0e4d16d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))\n",
        "G_loss\n",
        "# generator loss"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean_2:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpEgbPT9AsaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InS5ESeJNbWT",
        "colab_type": "text"
      },
      "source": [
        "optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b7oNCMGNd1o",
        "colab_type": "code",
        "outputId": "0a5160e6-b333-4ff4-9044-1d5f91d8478c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "learning_rate = 0.001\n",
        "tvars = tf.trainable_variables()\n",
        "\n",
        "d_vars = [var for var in tvars if 'dis' in var.name]\n",
        "g_vars = [var for var in tvars if 'gen' in var.name]\n",
        "\n",
        "print([v.name for v in d_vars])\n",
        "print([v.name for v in g_vars])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dis/dense/kernel:0', 'dis/dense/bias:0', 'dis/dense_1/kernel:0', 'dis/dense_1/bias:0', 'dis/dense_2/kernel:0', 'dis/dense_2/bias:0']\n",
            "['gen/dense/kernel:0', 'gen/dense/bias:0', 'gen/dense_1/kernel:0', 'gen/dense_1/bias:0', 'gen/dense_2/kernel:0', 'gen/dense_2/bias:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDxxz6aQNl9l",
        "colab_type": "code",
        "outputId": "f321f524-6ab5-45f3-be7b-53c43b26483a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
        "D_trainer\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Operation 'Adam' type=NoOp>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sab0GYJoNslS",
        "colab_type": "code",
        "outputId": "bf0b8127-0a1f-4b8e-aaeb-b5d0859f1c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)\n",
        "G_trainer\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Operation 'Adam_1' type=NoOp>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgHqbKE9Nxng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Session\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 500\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver(var_list=g_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH9BR3kLOEiS",
        "colab_type": "code",
        "outputId": "e540759a-3d87-4143-80d4-cdd675ad48d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Save a sample per epoch\n",
        "samples = []\n",
        "\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    # Recall an epoch is an entire run through the training data\n",
        "    for e in range(epochs):\n",
        "        # // indicates classic division\n",
        "        num_batches = mnist.train.num_examples // batch_size\n",
        "        \n",
        "        for i in range(num_batches):\n",
        "            \n",
        "            # Grab batch of images\n",
        "            batch = mnist.train.next_batch(batch_size)\n",
        "            \n",
        "            # Get images, reshape and rescale to pass to D\n",
        "            batch_images = batch[0].reshape((batch_size, 784))\n",
        "            batch_images = batch_images*2 - 1\n",
        "            \n",
        "            # Z (random latent noise data for Generator)\n",
        "            # -1 to 1 because of tanh activation\n",
        "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
        "            \n",
        "            # Run optimizers, no need to save outputs, we won't use them\n",
        "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
        "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
        "        \n",
        "            \n",
        "        print(\"Currently on Epoch {} of {} total...\".format(e+1, epochs))\n",
        "        \n",
        "        # Sample from generator as we're training for viewing afterwards\n",
        "        sample_z = np.random.uniform(-1, 1, size=(1, 100))\n",
        "        gen_sample = sess.run(generator(z ,reuse=True),feed_dict={z: sample_z})\n",
        "        \n",
        "        samples.append(gen_sample)\n",
        "        \n",
        "        saver.save(sess,'/content/drive/My Drive/Colab Notebooks/MNIST/model_500_epoch_model_ckpt/500_epoch_model.ckpt')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently on Epoch 1 of 500 total...\n",
            "Currently on Epoch 2 of 500 total...\n",
            "Currently on Epoch 3 of 500 total...\n",
            "Currently on Epoch 4 of 500 total...\n",
            "Currently on Epoch 5 of 500 total...\n",
            "Currently on Epoch 6 of 500 total...\n",
            "Currently on Epoch 7 of 500 total...\n",
            "Currently on Epoch 8 of 500 total...\n",
            "Currently on Epoch 9 of 500 total...\n",
            "Currently on Epoch 10 of 500 total...\n",
            "Currently on Epoch 11 of 500 total...\n",
            "Currently on Epoch 12 of 500 total...\n",
            "Currently on Epoch 13 of 500 total...\n",
            "Currently on Epoch 14 of 500 total...\n",
            "Currently on Epoch 15 of 500 total...\n",
            "Currently on Epoch 16 of 500 total...\n",
            "Currently on Epoch 17 of 500 total...\n",
            "Currently on Epoch 18 of 500 total...\n",
            "Currently on Epoch 19 of 500 total...\n",
            "Currently on Epoch 20 of 500 total...\n",
            "Currently on Epoch 21 of 500 total...\n",
            "Currently on Epoch 22 of 500 total...\n",
            "Currently on Epoch 23 of 500 total...\n",
            "Currently on Epoch 24 of 500 total...\n",
            "Currently on Epoch 25 of 500 total...\n",
            "Currently on Epoch 26 of 500 total...\n",
            "Currently on Epoch 27 of 500 total...\n",
            "Currently on Epoch 28 of 500 total...\n",
            "Currently on Epoch 29 of 500 total...\n",
            "Currently on Epoch 30 of 500 total...\n",
            "Currently on Epoch 31 of 500 total...\n",
            "Currently on Epoch 32 of 500 total...\n",
            "Currently on Epoch 33 of 500 total...\n",
            "Currently on Epoch 34 of 500 total...\n",
            "Currently on Epoch 35 of 500 total...\n",
            "Currently on Epoch 36 of 500 total...\n",
            "Currently on Epoch 37 of 500 total...\n",
            "Currently on Epoch 38 of 500 total...\n",
            "Currently on Epoch 39 of 500 total...\n",
            "Currently on Epoch 40 of 500 total...\n",
            "Currently on Epoch 41 of 500 total...\n",
            "Currently on Epoch 42 of 500 total...\n",
            "Currently on Epoch 43 of 500 total...\n",
            "Currently on Epoch 44 of 500 total...\n",
            "Currently on Epoch 45 of 500 total...\n",
            "Currently on Epoch 46 of 500 total...\n",
            "Currently on Epoch 47 of 500 total...\n",
            "Currently on Epoch 48 of 500 total...\n",
            "Currently on Epoch 49 of 500 total...\n",
            "Currently on Epoch 50 of 500 total...\n",
            "Currently on Epoch 51 of 500 total...\n",
            "Currently on Epoch 52 of 500 total...\n",
            "Currently on Epoch 53 of 500 total...\n",
            "Currently on Epoch 54 of 500 total...\n",
            "Currently on Epoch 55 of 500 total...\n",
            "Currently on Epoch 56 of 500 total...\n",
            "Currently on Epoch 57 of 500 total...\n",
            "Currently on Epoch 58 of 500 total...\n",
            "Currently on Epoch 59 of 500 total...\n",
            "Currently on Epoch 60 of 500 total...\n",
            "Currently on Epoch 61 of 500 total...\n",
            "Currently on Epoch 62 of 500 total...\n",
            "Currently on Epoch 63 of 500 total...\n",
            "Currently on Epoch 64 of 500 total...\n",
            "Currently on Epoch 65 of 500 total...\n",
            "Currently on Epoch 66 of 500 total...\n",
            "Currently on Epoch 67 of 500 total...\n",
            "Currently on Epoch 68 of 500 total...\n",
            "Currently on Epoch 69 of 500 total...\n",
            "Currently on Epoch 70 of 500 total...\n",
            "Currently on Epoch 71 of 500 total...\n",
            "Currently on Epoch 72 of 500 total...\n",
            "Currently on Epoch 73 of 500 total...\n",
            "Currently on Epoch 74 of 500 total...\n",
            "Currently on Epoch 75 of 500 total...\n",
            "Currently on Epoch 76 of 500 total...\n",
            "Currently on Epoch 77 of 500 total...\n",
            "Currently on Epoch 78 of 500 total...\n",
            "Currently on Epoch 79 of 500 total...\n",
            "Currently on Epoch 80 of 500 total...\n",
            "Currently on Epoch 81 of 500 total...\n",
            "Currently on Epoch 82 of 500 total...\n",
            "Currently on Epoch 83 of 500 total...\n",
            "Currently on Epoch 84 of 500 total...\n",
            "Currently on Epoch 85 of 500 total...\n",
            "Currently on Epoch 86 of 500 total...\n",
            "Currently on Epoch 87 of 500 total...\n",
            "Currently on Epoch 88 of 500 total...\n",
            "Currently on Epoch 89 of 500 total...\n",
            "Currently on Epoch 90 of 500 total...\n",
            "Currently on Epoch 91 of 500 total...\n",
            "Currently on Epoch 92 of 500 total...\n",
            "Currently on Epoch 93 of 500 total...\n",
            "Currently on Epoch 94 of 500 total...\n",
            "Currently on Epoch 95 of 500 total...\n",
            "Currently on Epoch 96 of 500 total...\n",
            "Currently on Epoch 97 of 500 total...\n",
            "Currently on Epoch 98 of 500 total...\n",
            "Currently on Epoch 99 of 500 total...\n",
            "Currently on Epoch 100 of 500 total...\n",
            "Currently on Epoch 101 of 500 total...\n",
            "Currently on Epoch 102 of 500 total...\n",
            "Currently on Epoch 103 of 500 total...\n",
            "Currently on Epoch 104 of 500 total...\n",
            "Currently on Epoch 105 of 500 total...\n",
            "Currently on Epoch 106 of 500 total...\n",
            "Currently on Epoch 107 of 500 total...\n",
            "Currently on Epoch 108 of 500 total...\n",
            "Currently on Epoch 109 of 500 total...\n",
            "Currently on Epoch 110 of 500 total...\n",
            "Currently on Epoch 111 of 500 total...\n",
            "Currently on Epoch 112 of 500 total...\n",
            "Currently on Epoch 113 of 500 total...\n",
            "Currently on Epoch 114 of 500 total...\n",
            "Currently on Epoch 115 of 500 total...\n",
            "Currently on Epoch 116 of 500 total...\n",
            "Currently on Epoch 117 of 500 total...\n",
            "Currently on Epoch 118 of 500 total...\n",
            "Currently on Epoch 119 of 500 total...\n",
            "Currently on Epoch 120 of 500 total...\n",
            "Currently on Epoch 121 of 500 total...\n",
            "Currently on Epoch 122 of 500 total...\n",
            "Currently on Epoch 123 of 500 total...\n",
            "Currently on Epoch 124 of 500 total...\n",
            "Currently on Epoch 125 of 500 total...\n",
            "Currently on Epoch 126 of 500 total...\n",
            "Currently on Epoch 127 of 500 total...\n",
            "Currently on Epoch 128 of 500 total...\n",
            "Currently on Epoch 129 of 500 total...\n",
            "Currently on Epoch 130 of 500 total...\n",
            "Currently on Epoch 131 of 500 total...\n",
            "Currently on Epoch 132 of 500 total...\n",
            "Currently on Epoch 133 of 500 total...\n",
            "Currently on Epoch 134 of 500 total...\n",
            "Currently on Epoch 135 of 500 total...\n",
            "Currently on Epoch 136 of 500 total...\n",
            "Currently on Epoch 137 of 500 total...\n",
            "Currently on Epoch 138 of 500 total...\n",
            "Currently on Epoch 139 of 500 total...\n",
            "Currently on Epoch 140 of 500 total...\n",
            "Currently on Epoch 141 of 500 total...\n",
            "Currently on Epoch 142 of 500 total...\n",
            "Currently on Epoch 143 of 500 total...\n",
            "Currently on Epoch 144 of 500 total...\n",
            "Currently on Epoch 145 of 500 total...\n",
            "Currently on Epoch 146 of 500 total...\n",
            "Currently on Epoch 147 of 500 total...\n",
            "Currently on Epoch 148 of 500 total...\n",
            "Currently on Epoch 149 of 500 total...\n",
            "Currently on Epoch 150 of 500 total...\n",
            "Currently on Epoch 151 of 500 total...\n",
            "Currently on Epoch 152 of 500 total...\n",
            "Currently on Epoch 153 of 500 total...\n",
            "Currently on Epoch 154 of 500 total...\n",
            "Currently on Epoch 155 of 500 total...\n",
            "Currently on Epoch 156 of 500 total...\n",
            "Currently on Epoch 157 of 500 total...\n",
            "Currently on Epoch 158 of 500 total...\n",
            "Currently on Epoch 159 of 500 total...\n",
            "Currently on Epoch 160 of 500 total...\n",
            "Currently on Epoch 161 of 500 total...\n",
            "Currently on Epoch 162 of 500 total...\n",
            "Currently on Epoch 163 of 500 total...\n",
            "Currently on Epoch 164 of 500 total...\n",
            "Currently on Epoch 165 of 500 total...\n",
            "Currently on Epoch 166 of 500 total...\n",
            "Currently on Epoch 167 of 500 total...\n",
            "Currently on Epoch 168 of 500 total...\n",
            "Currently on Epoch 169 of 500 total...\n",
            "Currently on Epoch 170 of 500 total...\n",
            "Currently on Epoch 171 of 500 total...\n",
            "Currently on Epoch 172 of 500 total...\n",
            "Currently on Epoch 173 of 500 total...\n",
            "Currently on Epoch 174 of 500 total...\n",
            "Currently on Epoch 175 of 500 total...\n",
            "Currently on Epoch 176 of 500 total...\n",
            "Currently on Epoch 177 of 500 total...\n",
            "Currently on Epoch 178 of 500 total...\n",
            "Currently on Epoch 179 of 500 total...\n",
            "Currently on Epoch 180 of 500 total...\n",
            "Currently on Epoch 181 of 500 total...\n",
            "Currently on Epoch 182 of 500 total...\n",
            "Currently on Epoch 183 of 500 total...\n",
            "Currently on Epoch 184 of 500 total...\n",
            "Currently on Epoch 185 of 500 total...\n",
            "Currently on Epoch 186 of 500 total...\n",
            "Currently on Epoch 187 of 500 total...\n",
            "Currently on Epoch 188 of 500 total...\n",
            "Currently on Epoch 189 of 500 total...\n",
            "Currently on Epoch 190 of 500 total...\n",
            "Currently on Epoch 191 of 500 total...\n",
            "Currently on Epoch 192 of 500 total...\n",
            "Currently on Epoch 193 of 500 total...\n",
            "Currently on Epoch 194 of 500 total...\n",
            "Currently on Epoch 195 of 500 total...\n",
            "Currently on Epoch 196 of 500 total...\n",
            "Currently on Epoch 197 of 500 total...\n",
            "Currently on Epoch 198 of 500 total...\n",
            "Currently on Epoch 199 of 500 total...\n",
            "Currently on Epoch 200 of 500 total...\n",
            "Currently on Epoch 201 of 500 total...\n",
            "Currently on Epoch 202 of 500 total...\n",
            "Currently on Epoch 203 of 500 total...\n",
            "Currently on Epoch 204 of 500 total...\n",
            "Currently on Epoch 205 of 500 total...\n",
            "Currently on Epoch 206 of 500 total...\n",
            "Currently on Epoch 207 of 500 total...\n",
            "Currently on Epoch 208 of 500 total...\n",
            "Currently on Epoch 209 of 500 total...\n",
            "Currently on Epoch 210 of 500 total...\n",
            "Currently on Epoch 211 of 500 total...\n",
            "Currently on Epoch 212 of 500 total...\n",
            "Currently on Epoch 213 of 500 total...\n",
            "Currently on Epoch 214 of 500 total...\n",
            "Currently on Epoch 215 of 500 total...\n",
            "Currently on Epoch 216 of 500 total...\n",
            "Currently on Epoch 217 of 500 total...\n",
            "Currently on Epoch 218 of 500 total...\n",
            "Currently on Epoch 219 of 500 total...\n",
            "Currently on Epoch 220 of 500 total...\n",
            "Currently on Epoch 221 of 500 total...\n",
            "Currently on Epoch 222 of 500 total...\n",
            "Currently on Epoch 223 of 500 total...\n",
            "Currently on Epoch 224 of 500 total...\n",
            "Currently on Epoch 225 of 500 total...\n",
            "Currently on Epoch 226 of 500 total...\n",
            "Currently on Epoch 227 of 500 total...\n",
            "Currently on Epoch 228 of 500 total...\n",
            "Currently on Epoch 229 of 500 total...\n",
            "Currently on Epoch 230 of 500 total...\n",
            "Currently on Epoch 231 of 500 total...\n",
            "Currently on Epoch 232 of 500 total...\n",
            "Currently on Epoch 233 of 500 total...\n",
            "Currently on Epoch 234 of 500 total...\n",
            "Currently on Epoch 235 of 500 total...\n",
            "Currently on Epoch 236 of 500 total...\n",
            "Currently on Epoch 237 of 500 total...\n",
            "Currently on Epoch 238 of 500 total...\n",
            "Currently on Epoch 239 of 500 total...\n",
            "Currently on Epoch 240 of 500 total...\n",
            "Currently on Epoch 241 of 500 total...\n",
            "Currently on Epoch 242 of 500 total...\n",
            "Currently on Epoch 243 of 500 total...\n",
            "Currently on Epoch 244 of 500 total...\n",
            "Currently on Epoch 245 of 500 total...\n",
            "Currently on Epoch 246 of 500 total...\n",
            "Currently on Epoch 247 of 500 total...\n",
            "Currently on Epoch 248 of 500 total...\n",
            "Currently on Epoch 249 of 500 total...\n",
            "Currently on Epoch 250 of 500 total...\n",
            "Currently on Epoch 251 of 500 total...\n",
            "Currently on Epoch 252 of 500 total...\n",
            "Currently on Epoch 253 of 500 total...\n",
            "Currently on Epoch 254 of 500 total...\n",
            "Currently on Epoch 255 of 500 total...\n",
            "Currently on Epoch 256 of 500 total...\n",
            "Currently on Epoch 257 of 500 total...\n",
            "Currently on Epoch 258 of 500 total...\n",
            "Currently on Epoch 259 of 500 total...\n",
            "Currently on Epoch 260 of 500 total...\n",
            "Currently on Epoch 261 of 500 total...\n",
            "Currently on Epoch 262 of 500 total...\n",
            "Currently on Epoch 263 of 500 total...\n",
            "Currently on Epoch 264 of 500 total...\n",
            "Currently on Epoch 265 of 500 total...\n",
            "Currently on Epoch 266 of 500 total...\n",
            "Currently on Epoch 267 of 500 total...\n",
            "Currently on Epoch 268 of 500 total...\n",
            "Currently on Epoch 269 of 500 total...\n",
            "Currently on Epoch 270 of 500 total...\n",
            "Currently on Epoch 271 of 500 total...\n",
            "Currently on Epoch 272 of 500 total...\n",
            "Currently on Epoch 273 of 500 total...\n",
            "Currently on Epoch 274 of 500 total...\n",
            "Currently on Epoch 275 of 500 total...\n",
            "Currently on Epoch 276 of 500 total...\n",
            "Currently on Epoch 277 of 500 total...\n",
            "Currently on Epoch 278 of 500 total...\n",
            "Currently on Epoch 279 of 500 total...\n",
            "Currently on Epoch 280 of 500 total...\n",
            "Currently on Epoch 281 of 500 total...\n",
            "Currently on Epoch 282 of 500 total...\n",
            "Currently on Epoch 283 of 500 total...\n",
            "Currently on Epoch 284 of 500 total...\n",
            "Currently on Epoch 285 of 500 total...\n",
            "Currently on Epoch 286 of 500 total...\n",
            "Currently on Epoch 287 of 500 total...\n",
            "Currently on Epoch 288 of 500 total...\n",
            "Currently on Epoch 289 of 500 total...\n",
            "Currently on Epoch 290 of 500 total...\n",
            "Currently on Epoch 291 of 500 total...\n",
            "Currently on Epoch 292 of 500 total...\n",
            "Currently on Epoch 293 of 500 total...\n",
            "Currently on Epoch 294 of 500 total...\n",
            "Currently on Epoch 295 of 500 total...\n",
            "Currently on Epoch 296 of 500 total...\n",
            "Currently on Epoch 297 of 500 total...\n",
            "Currently on Epoch 298 of 500 total...\n",
            "Currently on Epoch 299 of 500 total...\n",
            "Currently on Epoch 300 of 500 total...\n",
            "Currently on Epoch 301 of 500 total...\n",
            "Currently on Epoch 302 of 500 total...\n",
            "Currently on Epoch 303 of 500 total...\n",
            "Currently on Epoch 304 of 500 total...\n",
            "Currently on Epoch 305 of 500 total...\n",
            "Currently on Epoch 306 of 500 total...\n",
            "Currently on Epoch 307 of 500 total...\n",
            "Currently on Epoch 308 of 500 total...\n",
            "Currently on Epoch 309 of 500 total...\n",
            "Currently on Epoch 310 of 500 total...\n",
            "Currently on Epoch 311 of 500 total...\n",
            "Currently on Epoch 312 of 500 total...\n",
            "Currently on Epoch 313 of 500 total...\n",
            "Currently on Epoch 314 of 500 total...\n",
            "Currently on Epoch 315 of 500 total...\n",
            "Currently on Epoch 316 of 500 total...\n",
            "Currently on Epoch 317 of 500 total...\n",
            "Currently on Epoch 318 of 500 total...\n",
            "Currently on Epoch 319 of 500 total...\n",
            "Currently on Epoch 320 of 500 total...\n",
            "Currently on Epoch 321 of 500 total...\n",
            "Currently on Epoch 322 of 500 total...\n",
            "Currently on Epoch 323 of 500 total...\n",
            "Currently on Epoch 324 of 500 total...\n",
            "Currently on Epoch 325 of 500 total...\n",
            "Currently on Epoch 326 of 500 total...\n",
            "Currently on Epoch 327 of 500 total...\n",
            "Currently on Epoch 328 of 500 total...\n",
            "Currently on Epoch 329 of 500 total...\n",
            "Currently on Epoch 330 of 500 total...\n",
            "Currently on Epoch 331 of 500 total...\n",
            "Currently on Epoch 332 of 500 total...\n",
            "Currently on Epoch 333 of 500 total...\n",
            "Currently on Epoch 334 of 500 total...\n",
            "Currently on Epoch 335 of 500 total...\n",
            "Currently on Epoch 336 of 500 total...\n",
            "Currently on Epoch 337 of 500 total...\n",
            "Currently on Epoch 338 of 500 total...\n",
            "Currently on Epoch 339 of 500 total...\n",
            "Currently on Epoch 340 of 500 total...\n",
            "Currently on Epoch 341 of 500 total...\n",
            "Currently on Epoch 342 of 500 total...\n",
            "Currently on Epoch 343 of 500 total...\n",
            "Currently on Epoch 344 of 500 total...\n",
            "Currently on Epoch 345 of 500 total...\n",
            "Currently on Epoch 346 of 500 total...\n",
            "Currently on Epoch 347 of 500 total...\n",
            "Currently on Epoch 348 of 500 total...\n",
            "Currently on Epoch 349 of 500 total...\n",
            "Currently on Epoch 350 of 500 total...\n",
            "Currently on Epoch 351 of 500 total...\n",
            "Currently on Epoch 352 of 500 total...\n",
            "Currently on Epoch 353 of 500 total...\n",
            "Currently on Epoch 354 of 500 total...\n",
            "Currently on Epoch 355 of 500 total...\n",
            "Currently on Epoch 356 of 500 total...\n",
            "Currently on Epoch 357 of 500 total...\n",
            "Currently on Epoch 358 of 500 total...\n",
            "Currently on Epoch 359 of 500 total...\n",
            "Currently on Epoch 360 of 500 total...\n",
            "Currently on Epoch 361 of 500 total...\n",
            "Currently on Epoch 362 of 500 total...\n",
            "Currently on Epoch 363 of 500 total...\n",
            "Currently on Epoch 364 of 500 total...\n",
            "Currently on Epoch 365 of 500 total...\n",
            "Currently on Epoch 366 of 500 total...\n",
            "Currently on Epoch 367 of 500 total...\n",
            "Currently on Epoch 368 of 500 total...\n",
            "Currently on Epoch 369 of 500 total...\n",
            "Currently on Epoch 370 of 500 total...\n",
            "Currently on Epoch 371 of 500 total...\n",
            "Currently on Epoch 372 of 500 total...\n",
            "Currently on Epoch 373 of 500 total...\n",
            "Currently on Epoch 374 of 500 total...\n",
            "Currently on Epoch 375 of 500 total...\n",
            "Currently on Epoch 376 of 500 total...\n",
            "Currently on Epoch 377 of 500 total...\n",
            "Currently on Epoch 378 of 500 total...\n",
            "Currently on Epoch 379 of 500 total...\n",
            "Currently on Epoch 380 of 500 total...\n",
            "Currently on Epoch 381 of 500 total...\n",
            "Currently on Epoch 382 of 500 total...\n",
            "Currently on Epoch 383 of 500 total...\n",
            "Currently on Epoch 384 of 500 total...\n",
            "Currently on Epoch 385 of 500 total...\n",
            "Currently on Epoch 386 of 500 total...\n",
            "Currently on Epoch 387 of 500 total...\n",
            "Currently on Epoch 388 of 500 total...\n",
            "Currently on Epoch 389 of 500 total...\n",
            "Currently on Epoch 390 of 500 total...\n",
            "Currently on Epoch 391 of 500 total...\n",
            "Currently on Epoch 392 of 500 total...\n",
            "Currently on Epoch 393 of 500 total...\n",
            "Currently on Epoch 394 of 500 total...\n",
            "Currently on Epoch 395 of 500 total...\n",
            "Currently on Epoch 396 of 500 total...\n",
            "Currently on Epoch 397 of 500 total...\n",
            "Currently on Epoch 398 of 500 total...\n",
            "Currently on Epoch 399 of 500 total...\n",
            "Currently on Epoch 400 of 500 total...\n",
            "Currently on Epoch 401 of 500 total...\n",
            "Currently on Epoch 402 of 500 total...\n",
            "Currently on Epoch 403 of 500 total...\n",
            "Currently on Epoch 404 of 500 total...\n",
            "Currently on Epoch 405 of 500 total...\n",
            "Currently on Epoch 406 of 500 total...\n",
            "Currently on Epoch 407 of 500 total...\n",
            "Currently on Epoch 408 of 500 total...\n",
            "Currently on Epoch 409 of 500 total...\n",
            "Currently on Epoch 410 of 500 total...\n",
            "Currently on Epoch 411 of 500 total...\n",
            "Currently on Epoch 412 of 500 total...\n",
            "Currently on Epoch 413 of 500 total...\n",
            "Currently on Epoch 414 of 500 total...\n",
            "Currently on Epoch 415 of 500 total...\n",
            "Currently on Epoch 416 of 500 total...\n",
            "Currently on Epoch 417 of 500 total...\n",
            "Currently on Epoch 418 of 500 total...\n",
            "Currently on Epoch 419 of 500 total...\n",
            "Currently on Epoch 420 of 500 total...\n",
            "Currently on Epoch 421 of 500 total...\n",
            "Currently on Epoch 422 of 500 total...\n",
            "Currently on Epoch 423 of 500 total...\n",
            "Currently on Epoch 424 of 500 total...\n",
            "Currently on Epoch 425 of 500 total...\n",
            "Currently on Epoch 426 of 500 total...\n",
            "Currently on Epoch 427 of 500 total...\n",
            "Currently on Epoch 428 of 500 total...\n",
            "Currently on Epoch 429 of 500 total...\n",
            "Currently on Epoch 430 of 500 total...\n",
            "Currently on Epoch 431 of 500 total...\n",
            "Currently on Epoch 432 of 500 total...\n",
            "Currently on Epoch 433 of 500 total...\n",
            "Currently on Epoch 434 of 500 total...\n",
            "Currently on Epoch 435 of 500 total...\n",
            "Currently on Epoch 436 of 500 total...\n",
            "Currently on Epoch 437 of 500 total...\n",
            "Currently on Epoch 438 of 500 total...\n",
            "Currently on Epoch 439 of 500 total...\n",
            "Currently on Epoch 440 of 500 total...\n",
            "Currently on Epoch 441 of 500 total...\n",
            "Currently on Epoch 442 of 500 total...\n",
            "Currently on Epoch 443 of 500 total...\n",
            "Currently on Epoch 444 of 500 total...\n",
            "Currently on Epoch 445 of 500 total...\n",
            "Currently on Epoch 446 of 500 total...\n",
            "Currently on Epoch 447 of 500 total...\n",
            "Currently on Epoch 448 of 500 total...\n",
            "Currently on Epoch 449 of 500 total...\n",
            "Currently on Epoch 450 of 500 total...\n",
            "Currently on Epoch 451 of 500 total...\n",
            "Currently on Epoch 452 of 500 total...\n",
            "Currently on Epoch 453 of 500 total...\n",
            "Currently on Epoch 454 of 500 total...\n",
            "Currently on Epoch 455 of 500 total...\n",
            "Currently on Epoch 456 of 500 total...\n",
            "Currently on Epoch 457 of 500 total...\n",
            "Currently on Epoch 458 of 500 total...\n",
            "Currently on Epoch 459 of 500 total...\n",
            "Currently on Epoch 460 of 500 total...\n",
            "Currently on Epoch 461 of 500 total...\n",
            "Currently on Epoch 462 of 500 total...\n",
            "Currently on Epoch 463 of 500 total...\n",
            "Currently on Epoch 464 of 500 total...\n",
            "Currently on Epoch 465 of 500 total...\n",
            "Currently on Epoch 466 of 500 total...\n",
            "Currently on Epoch 467 of 500 total...\n",
            "Currently on Epoch 468 of 500 total...\n",
            "Currently on Epoch 469 of 500 total...\n",
            "Currently on Epoch 470 of 500 total...\n",
            "Currently on Epoch 471 of 500 total...\n",
            "Currently on Epoch 472 of 500 total...\n",
            "Currently on Epoch 473 of 500 total...\n",
            "Currently on Epoch 474 of 500 total...\n",
            "Currently on Epoch 475 of 500 total...\n",
            "Currently on Epoch 476 of 500 total...\n",
            "Currently on Epoch 477 of 500 total...\n",
            "Currently on Epoch 478 of 500 total...\n",
            "Currently on Epoch 479 of 500 total...\n",
            "Currently on Epoch 480 of 500 total...\n",
            "Currently on Epoch 481 of 500 total...\n",
            "Currently on Epoch 482 of 500 total...\n",
            "Currently on Epoch 483 of 500 total...\n",
            "Currently on Epoch 484 of 500 total...\n",
            "Currently on Epoch 485 of 500 total...\n",
            "Currently on Epoch 486 of 500 total...\n",
            "Currently on Epoch 487 of 500 total...\n",
            "Currently on Epoch 488 of 500 total...\n",
            "Currently on Epoch 489 of 500 total...\n",
            "Currently on Epoch 490 of 500 total...\n",
            "Currently on Epoch 491 of 500 total...\n",
            "Currently on Epoch 492 of 500 total...\n",
            "Currently on Epoch 493 of 500 total...\n",
            "Currently on Epoch 494 of 500 total...\n",
            "Currently on Epoch 495 of 500 total...\n",
            "Currently on Epoch 496 of 500 total...\n",
            "Currently on Epoch 497 of 500 total...\n",
            "Currently on Epoch 498 of 500 total...\n",
            "Currently on Epoch 499 of 500 total...\n",
            "Currently on Epoch 500 of 500 total...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9eEkUoHTqPg",
        "colab_type": "code",
        "outputId": "ec3173db-1606-4ccd-d5a2-cfdbc37852ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "saver = tf.train.Saver(var_list=g_vars)\n",
        "\n",
        "new_samples = []\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    saver.restore(sess,'/content/drive/My Drive/Colab Notebooks/MNIST/model_500_epoch_model_ckpt/500_epoch_model.ckpt')\n",
        "    \n",
        "    for x in range(5):\n",
        "        sample_z = np.random.uniform(-1,1,size=(1,100))\n",
        "        gen_sample = sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
        "        \n",
        "        new_samples.append(gen_sample)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Colab Notebooks/MNIST/model_500_epoch_model_ckpt/500_epoch_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rks2Yz0AOMtA",
        "colab_type": "code",
        "outputId": "f1c55726-ed9b-4be3-ef1c-ee5a8af0bf00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(samples[0].reshape(28,28),cmap='Greys')\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe208573fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEImgZBciEZTsQiSCkl2IRFCyC5EI/wvKcWaZicjOMQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nli7tDk1TUeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}